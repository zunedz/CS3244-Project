{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train:  (7767, 563) shape of test:  (3162, 563)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"./input/Train/train.csv\")\n",
    "test = pd.read_csv(\"./input/Test/test.csv\")\n",
    "\n",
    "print(\"shape of train: \", train.shape, \"shape of test: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.isnull().values.any())\n",
    "print(test.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: Train data and test data is divided in approximately 70:30. There are no missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations for Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.Activity.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (30,10))\n",
    "sns.countplot(x=train.Activity)\n",
    "plt.xlabel('Activity')\n",
    "plt.ylabel('count')\n",
    "plt.title('Frequency of Activities in Train Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked Bar Chart for different activities with regards to subjects\n",
    "\n",
    "stack_group = train.groupby(['subject', 'Activity']).size().unstack()\n",
    "stack_group.plot(kind='bar', stacked=True, figsize=(17, 8), title = 'Activity count w.r.t Subjects in train')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations for Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.Activity.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (30,10))\n",
    "sns.countplot(x=test.Activity)\n",
    "plt.xlabel('Activity')\n",
    "plt.ylabel('count')\n",
    "plt.title('Frequency of Activities in test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Stacked Bar Chart for different activities with regards to subjects\n",
    "\n",
    "stack_group = test.groupby(['subject', 'Activity']).size().unstack()\n",
    "stack_group.plot(kind='bar', stacked=True, figsize=(17, 8), title = 'Activity count w.r.t Subjects in test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we need to standardize the data to get better performance\n",
    "features = train.columns.values.tolist()\n",
    "features.remove('Activity')\n",
    "\n",
    "# Separating out the features\n",
    "x = train.loc[:, features].values\n",
    "\n",
    "# Separating out the target\n",
    "y = train.loc[:,['Activity']].values\n",
    "\n",
    "# Standardizing the features\n",
    "x = StandardScaler().fit_transform(x)\n",
    "\n",
    "train_features, validation_features, train_labels, validation_labels = train_test_split(x, y, test_size=0.25, random_state=1300)\n",
    "\n",
    "targets = train['Activity'].unique()\n",
    "\n",
    "train_labels = pd.DataFrame(train_labels, columns=['Activity'])\n",
    "validation_labels = pd.DataFrame(validation_labels, columns=['Activity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis (PCA)\n",
    "We want to use PCA to reduce the the multidimension features in our data into fewer dimensions to better understand the data distribution. We are interested to find out whether the classes are separable using these selected principal components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 Components PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_train = pca.fit_transform(train_features)\n",
    "principalDf = pd.DataFrame(data = X_train\n",
    "             , columns = ['PC1', 'PC2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDf = pd.concat([principalDf, train_labels], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('PC1', fontsize = 15)\n",
    "ax.set_ylabel('PC2', fontsize = 15)\n",
    "ax.set_title('PCA with 2 components', fontsize = 20)\n",
    "\n",
    "for target in targets:\n",
    "    indicesToKeep = finalDf['Activity'] == target\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, 'PC1']\n",
    "               , finalDf.loc[indicesToKeep, 'PC2']\n",
    "               , s = 50)\n",
    "ax.legend(targets)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result above we can see that the first principal component contains 48.08% of the variance and the second principal component contains 8.11% of the variance. Together, the two components contain 56.19% of the information, which is not very representative. The classes are also overlapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 Components PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca3 = PCA(n_components=3)\n",
    "PC3 = pca3.fit_transform(x)\n",
    "principalDf3 = pd.DataFrame(data = PC3\n",
    "             , columns = ['PC1', 'PC2', 'PC3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDf3 = pd.concat([principalDf3, train[['Activity']]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1, projection='3d') \n",
    "ax.set_xlabel('PC1', fontsize = 15)\n",
    "ax.set_ylabel('PC2', fontsize = 15)\n",
    "ax.set_zlabel('PC3', fontsize = 15)\n",
    "ax.set_title('PCA with 3 components', fontsize = 20)\n",
    "targets = train['Activity'].unique()\n",
    "\n",
    "for target in targets:\n",
    "    indicesToKeep = finalDf3['Activity'] == target\n",
    "    ax.scatter(finalDf3.loc[indicesToKeep, 'PC1']\n",
    "               , finalDf3.loc[indicesToKeep, 'PC2']\n",
    "               , finalDf3.loc[indicesToKeep, 'PC3']\n",
    "               , s = 50)\n",
    "ax.legend(targets)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca3.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the variance ratio above we can see that the first principal component contains 48.15% of the variance and the second principal component contains 8.08% of the variance, and the third principal component contains 3.19% of the variance. Together, the three components contain 59.42% of the information, which is still considerably small. The classes are again overlapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_n = PCA(n_components=120)\n",
    "PCN = pca_n.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(pca_n.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isomap Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we need to standardize the data to get better performance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "features = train.columns.values.tolist()\n",
    "features.remove('Activity')\n",
    "\n",
    "# Separating out the features\n",
    "x = train.loc[:, features].values\n",
    "\n",
    "# Separating out the target\n",
    "y = train.loc[:,['Activity']].values\n",
    "\n",
    "# Standardizing the features\n",
    "x = StandardScaler().fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import Isomap as ISO\n",
    "\n",
    "iso = ISO(n_components = 2)\n",
    "isomap = iso.fit_transform(x)\n",
    "isomapTempDf = pd.DataFrame(data = isomap, columns = [\"ISO1\", \"ISO2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isomapFinalDf = pd.concat([isomapTempDf, train[['Activity']]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (16,10))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('ISO1', fontsize = 15)\n",
    "ax.set_ylabel('ISO2', fontsize = 15)\n",
    "ax.set_title('Isomap Embedding', fontsize = 20)\n",
    "targets = train['Activity'].unique()\n",
    "\n",
    "for target in targets:\n",
    "    indicesToKeep = isomapFinalDf['Activity'] == target\n",
    "    ax.scatter(isomapFinalDf.loc[indicesToKeep, 'ISO1']\n",
    "               , isomapFinalDf.loc[indicesToKeep, 'ISO2']\n",
    "               , s = 30\n",
    "               , alpha = 0.5)\n",
    "ax.legend(targets)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isomap.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-Distributed Stochastic Neighbour Embedding (t-SNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-34bd92af1aa8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanifold\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtsne\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperplexity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtsne_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf_subset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'tsne-2d-one'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'tsne-2d-two'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Activities'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    884\u001b[0m             \u001b[0mEmbedding\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlow\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mdimensional\u001b[0m \u001b[0mspace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m         \"\"\"\n\u001b[1;32m--> 886\u001b[1;33m         \u001b[0membedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    887\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, skip_num_points)\u001b[0m\n\u001b[0;32m    751\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m             \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 753\u001b[1;33m             \u001b[0mdistances_nn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'distance'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    754\u001b[0m             \u001b[0mduration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors_graph\u001b[1;34m(self, X, n_neighbors, mode)\u001b[0m\n\u001b[0;32m    761\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'distance'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m             A_data, A_ind = self.kneighbors(\n\u001b[1;32m--> 763\u001b[1;33m                 X, n_neighbors, return_distance=True)\n\u001b[0m\u001b[0;32m    764\u001b[0m             \u001b[0mA_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    661\u001b[0m                 delayed_query(\n\u001b[0;32m    662\u001b[0m                     self._tree, X[s], n_neighbors, return_distance)\n\u001b[1;32m--> 663\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    664\u001b[0m             )\n\u001b[0;32m    665\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1002\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1003\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    833\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36m_tree_query_parallel_helper\u001b[1;34m(tree, *args, **kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m     \u001b[0munder\u001b[0m \u001b[0mPyPy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m     \"\"\"\n\u001b[1;32m--> 490\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components = 2, perplexity = 50, n_iter = 2500)\n",
    "tsne_results = tsne.fit_transform(train_features)\n",
    "\n",
    "df_subset = pd.DataFrame(columns = ['tsne-2d-one','tsne-2d-two', 'Activities'])\n",
    "df_subset['tsne-2d-one'] = tsne_results[:, 0]\n",
    "df_subset['tsne-2d-two'] = tsne_results[:, 1]\n",
    "df_subset['Activities'] = train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16, 10))\n",
    "plt.title('t-SNE with 2 Components')\n",
    "\n",
    "sns.scatterplot(\n",
    "    x = \"tsne-2d-one\", y = \"tsne-2d-two\",\n",
    "    hue = \"Activities\",\n",
    "    palette = \"bright\",\n",
    "    data = df_subset,\n",
    "    legend = \"full\",\n",
    "    alpha = 0.3\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=120, random_state = 1300)  \n",
    "X_train = pca.fit_transform(train_features)  \n",
    "X_val = pca.transform(validation_features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.score(X_val, validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.score(X_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on number of trees\n",
    "clf_RF_n = [RandomForestClassifier(n_estimators = 50, random_state  = 1300),\n",
    "            RandomForestClassifier(n_estimators = 150, random_state  = 1300),\n",
    "            RandomForestClassifier(n_estimators = 200, random_state  = 1300),\n",
    "            RandomForestClassifier(n_estimators = 400, random_state  = 1300),\n",
    "            RandomForestClassifier(n_estimators = 500, random_state  = 1300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "acc_RF_n = []\n",
    "ex_time_RF_n = []\n",
    "\n",
    "for clf in clf_RF_n:\n",
    "    start_time = timer()\n",
    "    fit = clf.fit(X_train, np.ravel(train_labels))\n",
    "    pred = fit.predict(X_val)\n",
    "    accuracy = accuracy_score(validation_labels, pred)\n",
    "    elapsed = timer() - start_time\n",
    "    \n",
    "    ex_time_RF_n.append(elapsed)\n",
    "    acc_RF_n.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_RF_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphical Representation of ACCURACY and EXECUTION Time for RANDOM FOREST CLASSIFIER\n",
    "\n",
    "label = ('n=50','n=150','n=200','n=400','n=500')\n",
    "Accu = acc_RF_n\n",
    "ExTime = ex_time_RF_n\n",
    "\n",
    "plt.figure(figsize = (15,8))\n",
    "y_pos = np.arange(len(label))\n",
    "\n",
    "#Accuracy\n",
    "plt.subplot(2,1,1)\n",
    "plt.bar(y_pos, Accu, align='center')\n",
    "plt.xticks(y_pos, label)\n",
    "plt.ylim(min(Accu)- 0.01 , max(Accu) +0.01)\n",
    "plt.ylabel('Accuracy Percentage')\n",
    "\n",
    "#Execution Time\n",
    "plt.subplot(2,1,2)\n",
    "plt.bar(y_pos, ExTime, align='center', color = 'g')\n",
    "plt.xticks(y_pos, label)\n",
    "plt.ylim(min(ExTime)- 5 , max(ExTime) +5)\n",
    "plt.ylabel('Run-Time(sec)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_RF_d = [RandomForestClassifier(n_estimators = 200, max_depth = 10, random_state  = 1300),\n",
    "            RandomForestClassifier(n_estimators = 200, max_depth = 20, random_state  = 1300),\n",
    "            RandomForestClassifier(n_estimators = 200, max_depth = 40, random_state  = 1300),\n",
    "            RandomForestClassifier(n_estimators = 200, max_depth = 50,random_state  = 1300),\n",
    "            RandomForestClassifier(n_estimators = 200, max_depth = 70, random_state  = 1300),\n",
    "            RandomForestClassifier(n_estimators = 200, max_depth = 200, random_state  = 1300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_time_RF_d = []\n",
    "acc_RF_d = []\n",
    "\n",
    "for clf in clf_RF_d :\n",
    "    start_time = timer()\n",
    "    fit = clf.fit(X_train, np.ravel(train_labels))\n",
    "    pred = fit.predict(X_test)\n",
    "    accuracy = accuracy_score(validation_labels, pred)\n",
    "    elapsed = timer() - start_time\n",
    "    \n",
    "    ex_time_RF_d.append(elapsed)\n",
    "    acc_RF_d.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphical Representation of ACCURACY and Execution Time for Random Forest with n = 200 and different max depths of a tree.\n",
    "\n",
    "label = ('d =10','d =20','d =40','d =50','d =70', ' d =200')\n",
    "Accu = acc_RF_d\n",
    "ExTime = ex_time_RF_d\n",
    "\n",
    "\n",
    "plt.figure(figsize = (15,8))\n",
    "y_pos = np.arange(len(label))\n",
    "\n",
    "#Accuracy\n",
    "plt.subplot(2,1,1)\n",
    "plt.bar(y_pos, Accu, align='center')\n",
    "plt.xticks(y_pos, label)\n",
    "plt.ylim(min(Accu)- 0.01 , max(Accu) +0.01)\n",
    "plt.ylabel('Accuracy Percentage')\n",
    "\n",
    "#Execution Time\n",
    "plt.subplot(2,1,2)\n",
    "plt.bar(y_pos, ExTime, align='center', color = 'g')\n",
    "plt.xticks(y_pos, label)\n",
    "plt.ylim(min(ExTime)- 5 , max(ExTime) +5)\n",
    "plt.ylabel('Run-Time(sec)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing performance for different methods of dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure the accuracy using Random Forest Classifier, number of tree = 140, maximum depth = 40, random seed = 1300\n",
    "# data is transformed with PCA\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "label = [\"Activity\"]\n",
    "features = list(train.columns)[:-1]\n",
    "\n",
    "# varying number of features for PCA\n",
    "\n",
    "def n_PCA(n):\n",
    "    pca = PCA(n_components = n, random_state = 1300)\n",
    "    X_train = pca.fit_transform(train_features)\n",
    "    X_validation = pca.transform(validation_features)\n",
    "    return X_train, X_validation #return the transformed data both train and validation\n",
    "\n",
    "accuracy = []\n",
    "\n",
    "for i in range(2, 10):\n",
    "    X_train, X_validation = n_PCA(i)\n",
    "    y_train, y_validation = train_labels.values.ravel(), validation_labels.values.ravel()\n",
    "    rfc = RFC(n_estimators = 140, max_depth = 40, random_state = 1300)\n",
    "    model = rfc.fit(X_train, y_train)\n",
    "    rfc_accuracy = model.score(X_validation, y_validation)\n",
    "    accuracy.append([i, rfc_accuracy])\n",
    "    \n",
    "for i in range(10, 200, 10):\n",
    "    X_train, X_validation = n_PCA(i)\n",
    "    y_train, y_validation = train_labels.values.ravel(), validation_labels.values.ravel()\n",
    "    rfc = RFC(n_estimators = 140, max_depth = 40, random_state = 1300)\n",
    "    model = rfc.fit(X_train, y_train)\n",
    "    rfc_accuracy = model.score(X_validation, y_validation)\n",
    "    accuracy.append([i, rfc_accuracy])\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the accuracy vs number of PCA features\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize = (10,6))\n",
    "plt.plot(list(map(lambda x: x[0], accuracy)), list(map(lambda x: x[1], accuracy)), color = \"r\")\n",
    "plt.xlabel(\"Number of features in PCA\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy vs Number of Features in PCA\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum accuracy attained at n =  120 \n",
      "with the accuracy of =  0.9289392378990731\n"
     ]
    }
   ],
   "source": [
    "# highest accuracy with PCA\n",
    "\n",
    "max_accuracy_PCA = max(accuracy, key = lambda x:x[1])\n",
    "print(\"maximum accuracy attained at n = \", max_accuracy_PCA[0], \"\\nwith the accuracy of = \", max_accuracy_PCA[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9402677651905252\n"
     ]
    }
   ],
   "source": [
    "# data is transform using t-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def n_TSNE(n, perplexity):\n",
    "    tsne = TSNE(n_components = n, perplexity = perplexity, n_iter = 2500, random_state = 1300)\n",
    "    train_validation_combined = np.append(train_features, validation_features, axis = 0)\n",
    "    X_combined = tsne.fit_transform(train_validation_combined)\n",
    "    X_train, X_validation = X_combined[:len(train_features)], X_combined[len(train_features):] \n",
    "    return X_train, X_validation #return the transformed data both train and validation\n",
    "\n",
    "# Model accuracy with Random Forest Classifier\n",
    "\n",
    "X_train, X_validation = n_TSNE(2, 50)\n",
    "y_train, y_validation = train_labels.values.ravel(), validation_labels.values.ravel()\n",
    "rfc = RFC(n_estimators = 140, max_depth = 40, random_state = 1300)\n",
    "model = rfc.fit(X_train, y_train)\n",
    "rfc_accuracy = model.score(X_validation, y_validation)\n",
    "print(rfc_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7198764160659115\n",
      "0.8377960865087538\n",
      "0.8486096807415036\n",
      "0.8558187435633368\n",
      "0.8671472708547889\n",
      "0.8717816683831102\n",
      "0.8717816683831102\n",
      "0.8748712667353244\n",
      "0.880020597322348\n",
      "0.8815653964984552\n"
     ]
    }
   ],
   "source": [
    "# data is transformed using ISOMAP embedding\n",
    "from sklearn.manifold import Isomap\n",
    "\n",
    "def n_isomap(n, neighbors):\n",
    "    iso = Isomap(n_components = n, n_neighbors = neighbors)\n",
    "    X_train = iso.fit_transform(train_features)\n",
    "    X_validation = iso.transform(validation_features)\n",
    "    return X_train, X_validation\n",
    "\n",
    "accuracy_isomap = []\n",
    "for i in range(2, 10):\n",
    "    X_train, X_validation = n_isomap(i, 5)\n",
    "    y_train, y_validation = train_labels.values.ravel(), validation_labels.values.ravel()\n",
    "    rfc = RFC(n_estimators = 140, max_depth = 40, random_state = 1300)\n",
    "    model = rfc.fit(X_train, y_train)\n",
    "    rfc_accuracy = model.score(X_validation, y_validation)\n",
    "    print(rfc_accuracy)\n",
    "    accuracy_isomap.append(rfc_accuracy)\n",
    "\n",
    "for i in range(10, 200, 10):\n",
    "    X_train, X_validation = n_isomap(i, 5)\n",
    "    y_train, y_validation = train_labels.values.ravel(), validation_labels.values.ravel()\n",
    "    rfc = RFC(n_estimators = 140, max_depth = 40, random_state = 1300)\n",
    "    model = rfc.fit(X_train, y_train)\n",
    "    rfc_accuracy = model.score(X_validation, y_validation)\n",
    "    print(rfc_accuracy)\n",
    "    accuracy_isomap.append(rfc_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the current model (Random Forest) based on F1 Score, run time Recall and Precision\n",
    "\n",
    "**Will add the rest once andrea adds the smote function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import package used\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from timeit import default_timer as timer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the data for training\n",
    "\n",
    "#Separating features and response for training data\n",
    "xtrain_features = train.iloc[:,:-1]\n",
    "xtrain_label = train['Activity']\n",
    "\n",
    "#Separating features and response for test data\n",
    "test_features = train.iloc[:,:-1]\n",
    "test_label = train['Activity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of labels\n",
    "activity_label = pd.Series(test.Activity.values).unique()\n",
    "\n",
    "activity_label_fixed = ['STANDING', 'SITTING', 'LAYING', 'WALKING', 'WALKING_DOWNSTAIRS',\n",
    "       'WALKING_UPSTAIRS']\n",
    "\n",
    "activity_label_moving = ['STAND_TO_SIT', 'SIT_TO_STAND',\n",
    "       'STAND_TO_LIE', 'LIE_TO_SIT', 'SIT_TO_LIE',\n",
    "       'LIE_TO_STAND']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert everything to numpy array to fit into the model\n",
    "X_labels = np.array(xtrain_label)\n",
    "X_features = np.array(xtrain_features)\n",
    "\n",
    "test_labels = np.array(test_label)\n",
    "test_features = np.array(test_features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting train data into validation and train, at using 20-80 ratio, with random state = 1300\n",
    "\n",
    "train_features, val_features, train_labels, val_labels = train_test_split(X_features, X_labels, test_size=0.2, random_state=1300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_features: (6213, 562) train_labels:  (6213,) val_features:  (1554, 562) val_labels: (1554,)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_features:\", train_features.shape, \"train_labels: \", train_labels.shape , \"val_features: \", val_features.shape, \"val_labels:\" , val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do Dimentionality Reduction, Principal Component Analysis, with n_components = 120 (As found above), with random state = 1300\n",
    "# Do it after splitting to prevent snooping\n",
    "\n",
    "pca = PCA(n_components=120, random_state = 1300)  \n",
    "X_train = pca.fit_transform(train_features)  \n",
    "X_val = pca.transform(val_features)  \n",
    "X_test = pca.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running RandomForest with depth = 40, random state = 1300 for validation set\n",
    "clf = RandomForestClassifier(n_estimators = 150, max_depth = 40, max_features= 'log2', random_state = 1300)\n",
    "\n",
    "start_time = timer()\n",
    "fit = clf.fit(train_features, train_labels)\n",
    "pred_val = fit.predict(val_features)\n",
    "\n",
    "\n",
    "#Get evaluation metric\n",
    "accuracy_val = accuracy_score(val_labels, pred_val)\n",
    "elapsed_val = timer() - start_time\n",
    "f1_val = f1_score(val_labels, pred_val, average = None, labels = activity_label)\n",
    "avgf1_val = f1_score(val_labels, pred_val, average = \"micro\") #Using micro as labels are under represented\n",
    "recall_val = recall_score(val_labels, pred_val, average = None, labels = activity_label)\n",
    "avgrecall_val = recall_score(val_labels, pred_val, average = \"micro\") #Using micro as labels are under represented\n",
    "precision_val = precision_score(val_labels, pred_val, average = None, labels = activity_label)\n",
    "avgprec_val = precision_score(val_labels, pred_val, average = \"micro\") #Using micro as labels are under represented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Validation Set:  0.9716859716859717\n",
      "Average Precision Score of Validation Set:  0.9716859716859717\n",
      "Average Recall Score of Validation Set:  0.9716859716859717\n",
      "Average F1 Score of Validation Set:  0.9716859716859717\n",
      "Run Time of Validation Set: 5.750156599999997\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Validation Set: \", accuracy_val)\n",
    "print(\"Average Precision Score of Validation Set: \", avgprec_val)\n",
    "print(\"Average Recall Score of Validation Set: \", avgrecall_val)\n",
    "print(\"Average F1 Score of Validation Set: \", avgf1_val)\n",
    "print(\"Run Time of Validation Set:\", elapsed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STANDING</th>\n",
       "      <th>STAND_TO_SIT</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>SIT_TO_STAND</th>\n",
       "      <th>STAND_TO_LIE</th>\n",
       "      <th>LAYING</th>\n",
       "      <th>LIE_TO_SIT</th>\n",
       "      <th>SIT_TO_LIE</th>\n",
       "      <th>LIE_TO_STAND</th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.967851</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994652</td>\n",
       "      <td>0.987835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall Score</th>\n",
       "      <td>0.976109</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision Score</th>\n",
       "      <td>0.959732</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989362</td>\n",
       "      <td>0.985437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 STANDING  STAND_TO_SIT   SITTING  SIT_TO_STAND  STAND_TO_LIE  \\\n",
       "F1 Score         0.967851      0.444444  0.963504      0.666667      0.756757   \n",
       "Recall Score     0.976109      0.333333  0.956522      0.500000      0.823529   \n",
       "Precision Score  0.959732      0.666667  0.970588      1.000000      0.700000   \n",
       "\n",
       "                 LAYING  LIE_TO_SIT  SIT_TO_LIE  LIE_TO_STAND  WALKING  \\\n",
       "F1 Score            1.0    0.740741    0.709677      0.421053      1.0   \n",
       "Recall Score        1.0    0.909091    0.733333      0.285714      1.0   \n",
       "Precision Score     1.0    0.625000    0.687500      0.800000      1.0   \n",
       "\n",
       "                 WALKING_DOWNSTAIRS  WALKING_UPSTAIRS  \n",
       "F1 Score                   0.994652          0.987835  \n",
       "Recall Score               1.000000          0.990244  \n",
       "Precision Score            0.989362          0.985437  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([f1_val] + [recall_val] + [precision_val], columns = activity_label, index = [\"F1 Score\", \"Recall Score\", \"Precision Score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Validation set, it seems like the scores for the average and accuracy seem to be acceptable (Around 97%)\n",
    "\n",
    "But when we look at the individual F1/Precision/Recall score, it seems that the transitional labels all generally have signficantly lower score compared to the stationary action labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running RandomForest with depth = 40, random state = 1300 for test set\n",
    "\n",
    "start_time = timer()\n",
    "fit_test = clf.fit(train_features, train_labels)\n",
    "pred_test = fit_test.predict(test_features)\n",
    "\n",
    "#Get etestuation metric\n",
    "accuracy_test = accuracy_score(test_labels, pred_test)\n",
    "elapsed_test = timer() - start_time\n",
    "f1_test = f1_score(test_labels, pred_test, average = None, labels = activity_label)\n",
    "avgf1_test = f1_score(test_labels, pred_test, average = \"macro\") #Using micro as labels are under represented\n",
    "recall_test = recall_score(test_labels, pred_test, average = None, labels = activity_label)\n",
    "avgrecall_test = recall_score(test_labels, pred_test, average = \"micro\") #Using micro as labels are under represented\n",
    "precision_test = precision_score(test_labels, pred_test, average = None, labels = activity_label)\n",
    "avgprec_test = precision_score(test_labels, pred_test, average = \"micro\") #Using micro as labels are under represented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test Set:  0.9943350070812411\n",
      "Average Precision Score of Test Set:  0.9943350070812411\n",
      "Average Recall Score of Test Set:  0.9943350070812411\n",
      "Average F1 Score of Test Set:  0.969628050235721\n",
      "Run Time of Test Set: 5.660717499999997\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Test Set: \", accuracy_test)\n",
    "print(\"Average Precision Score of Test Set: \", avgprec_test)\n",
    "print(\"Average Recall Score of Test Set: \", avgrecall_test)\n",
    "print(\"Average F1 Score of Test Set: \", avgf1_test)\n",
    "print(\"Run Time of Test Set:\", elapsed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STANDING</th>\n",
       "      <th>STAND_TO_SIT</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>SIT_TO_STAND</th>\n",
       "      <th>STAND_TO_LIE</th>\n",
       "      <th>LAYING</th>\n",
       "      <th>LIE_TO_SIT</th>\n",
       "      <th>SIT_TO_LIE</th>\n",
       "      <th>LIE_TO_STAND</th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.993336</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.992254</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>0.940397</td>\n",
       "      <td>0.895238</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998988</td>\n",
       "      <td>0.997671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall Score</th>\n",
       "      <td>0.995081</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.990719</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision Score</th>\n",
       "      <td>0.991597</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.993794</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997978</td>\n",
       "      <td>0.997207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 STANDING  STAND_TO_SIT   SITTING  SIT_TO_STAND  STAND_TO_LIE  \\\n",
       "F1 Score         0.993336      0.945055  0.992254      0.977778      0.950820   \n",
       "Recall Score     0.995081      0.914894  0.990719      0.956522      0.966667   \n",
       "Precision Score  0.991597      0.977273  0.993794      1.000000      0.935484   \n",
       "\n",
       "                 LAYING  LIE_TO_SIT  SIT_TO_LIE  LIE_TO_STAND  WALKING  \\\n",
       "F1 Score            1.0    0.944000    0.940397      0.895238      1.0   \n",
       "Recall Score        1.0    0.983333    0.946667      0.824561      1.0   \n",
       "Precision Score     1.0    0.907692    0.934211      0.979167      1.0   \n",
       "\n",
       "                 WALKING_DOWNSTAIRS  WALKING_UPSTAIRS  \n",
       "F1 Score                   0.998988          0.997671  \n",
       "Recall Score               1.000000          0.998136  \n",
       "Precision Score            0.997978          0.997207  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([f1_test] + [recall_test] + [precision_test], columns = activity_label, index = [\"F1 Score\", \"Recall Score\", \"Precision Score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to check using the PCA data instead to see if there are any improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running RandomForest with depth = 40, random state = 1300 for PCA validation set\n",
    "clf = RandomForestClassifier(n_estimators = 150, max_depth = 40, max_features= 'log2', random_state = 1300)\n",
    "\n",
    "start_time = timer()\n",
    "fit = clf.fit(X_train, train_labels)\n",
    "pred_val2 = fit.predict(X_val)\n",
    "\n",
    "\n",
    "#Get evaluation metric\n",
    "accuracy_val2 = accuracy_score(val_labels, pred_val2)\n",
    "elapsed_val2 = timer() - start_time\n",
    "f1_val2 = f1_score(val_labels, pred_val2, average = None, labels = activity_label)\n",
    "avgf1_val2 = f1_score(val_labels, pred_val2, average = \"micro\") #Using micro as labels are under represented\n",
    "recall_val2 = recall_score(val_labels, pred_val2, average = None, labels = activity_label)\n",
    "avgrecall_val2 = recall_score(val_labels, pred_val2, average = \"micro\") #Using micro as labels are under represented\n",
    "precision_val2 = precision_score(val_labels, pred_val2, average = None, labels = activity_label, zero_division = 0)\n",
    "avgprec_val2 = precision_score(val_labels, pred_val2, average = \"micro\") #Using micro as labels are under represented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, a warning appeared as the label \"SIT_TO_STAND\" was predicted 0 times. Hence TP + FP = 0, causing precision to give an warning. So it was set to 0 by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label that had 0 predictions:  {'SIT_TO_STAND'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Label that had 0 predictions: \", set(val_labels) - set(pred_val2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Validation Set:  0.9247104247104247\n",
      "Average Precision Score of Validation Set:  0.9247104247104247\n",
      "Average Recall Score of Validation Set:  0.9247104247104247\n",
      "Average F1 Score of Validation Set:  0.9247104247104247\n",
      "Run Time of Validation Set: 4.78855139999996\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Validation Set: \", accuracy_val2)\n",
    "print(\"Average Precision Score of Validation Set: \", avgprec_val2)\n",
    "print(\"Average Recall Score of Validation Set: \", avgrecall_val2)\n",
    "print(\"Average F1 Score of Validation Set: \", avgf1_val2)\n",
    "print(\"Run Time of Validation Set:\", elapsed_val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STANDING</th>\n",
       "      <th>STAND_TO_SIT</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>SIT_TO_STAND</th>\n",
       "      <th>STAND_TO_LIE</th>\n",
       "      <th>LAYING</th>\n",
       "      <th>LIE_TO_SIT</th>\n",
       "      <th>SIT_TO_LIE</th>\n",
       "      <th>LIE_TO_STAND</th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.900813</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.872865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.989796</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.985386</td>\n",
       "      <td>0.949333</td>\n",
       "      <td>0.944578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall Score</th>\n",
       "      <td>0.945392</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.991597</td>\n",
       "      <td>0.956989</td>\n",
       "      <td>0.956098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision Score</th>\n",
       "      <td>0.860248</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916335</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.979253</td>\n",
       "      <td>0.941799</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 STANDING  STAND_TO_SIT   SITTING  SIT_TO_STAND  STAND_TO_LIE  \\\n",
       "F1 Score         0.900813      0.500000  0.872865           0.0      0.645161   \n",
       "Recall Score     0.945392      0.333333  0.833333           0.0      0.588235   \n",
       "Precision Score  0.860248      1.000000  0.916335           0.0      0.714286   \n",
       "\n",
       "                   LAYING  LIE_TO_SIT  SIT_TO_LIE  LIE_TO_STAND   WALKING  \\\n",
       "F1 Score         0.989796    0.500000    0.583333      0.400000  0.985386   \n",
       "Recall Score     1.000000    0.545455    0.466667      0.285714  0.991597   \n",
       "Precision Score  0.979798    0.461538    0.777778      0.666667  0.979253   \n",
       "\n",
       "                 WALKING_DOWNSTAIRS  WALKING_UPSTAIRS  \n",
       "F1 Score                   0.949333          0.944578  \n",
       "Recall Score               0.956989          0.956098  \n",
       "Precision Score            0.941799          0.933333  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([f1_val2] + [recall_val2] + [precision_val2], columns = activity_label, index = [\"F1 Score\", \"Recall Score\", \"Precision Score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running RandomForest with depth = 40, random state = 1300 for test set\n",
    "\n",
    "start_time = timer()\n",
    "fit_test2 = clf.fit(X_train, train_labels)\n",
    "pred_test2 = fit_test2.predict(X_test)\n",
    "\n",
    "#Get etest2uation metric\n",
    "accuracy_test2 = accuracy_score(test_labels, pred_test2)\n",
    "elapsed_test2 = timer() - start_time\n",
    "f1_test2 = f1_score(test_labels, pred_test2, average = None, labels = activity_label)\n",
    "avgf1_test2 = f1_score(test_labels, pred_test2, average = \"macro\") #Using micro as labels are under represented\n",
    "recall_test2 = recall_score(test_labels, pred_test2, average = None, labels = activity_label)\n",
    "avgrecall_test2 = recall_score(test_labels, pred_test2, average = \"micro\") #Using micro as labels are under represented\n",
    "precision_test2 = precision_score(test_labels, pred_test2, average = None, labels = activity_label)\n",
    "avgprec_test2 = precision_score(test_labels, pred_test2, average = \"micro\") #Using micro as labels are under represented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test Set:  0.984936268829664\n",
      "Average Precision Score of Test Set:  0.984936268829664\n",
      "Average Recall Score of Test Set:  0.984936268829664\n",
      "Average F1 Score of Test Set:  0.9578574361023887\n",
      "Run Time of Test Set: 5.188065999999935\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Test Set: \", accuracy_test2)\n",
    "print(\"Average Precision Score of Test Set: \", avgprec_test2)\n",
    "print(\"Average Recall Score of Test Set: \", avgrecall_test2)\n",
    "print(\"Average F1 Score of Test Set: \", avgf1_test2)\n",
    "print(\"Run Time of Test Set:\", elapsed_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STANDING</th>\n",
       "      <th>STAND_TO_SIT</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>SIT_TO_STAND</th>\n",
       "      <th>STAND_TO_LIE</th>\n",
       "      <th>LAYING</th>\n",
       "      <th>LIE_TO_SIT</th>\n",
       "      <th>SIT_TO_LIE</th>\n",
       "      <th>LIE_TO_STAND</th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.978783</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.973838</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.937853</td>\n",
       "      <td>0.997881</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.997149</td>\n",
       "      <td>0.990389</td>\n",
       "      <td>0.989307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall Score</th>\n",
       "      <td>0.988756</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.964424</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.922222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.998369</td>\n",
       "      <td>0.991895</td>\n",
       "      <td>0.991612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision Score</th>\n",
       "      <td>0.969008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983438</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954023</td>\n",
       "      <td>0.995772</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.995932</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.987013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 STANDING  STAND_TO_SIT   SITTING  SIT_TO_STAND  STAND_TO_LIE  \\\n",
       "F1 Score         0.978783      0.955556  0.973838      0.954545      0.937853   \n",
       "Recall Score     0.988756      0.914894  0.964424      0.913043      0.922222   \n",
       "Precision Score  0.969008      1.000000  0.983438      1.000000      0.954023   \n",
       "\n",
       "                   LAYING  LIE_TO_SIT  SIT_TO_LIE  LIE_TO_STAND   WALKING  \\\n",
       "F1 Score         0.997881    0.901639    0.930556      0.886792  0.997149   \n",
       "Recall Score     1.000000    0.916667    0.893333      0.824561  0.998369   \n",
       "Precision Score  0.995772    0.887097    0.971014      0.959184  0.995932   \n",
       "\n",
       "                 WALKING_DOWNSTAIRS  WALKING_UPSTAIRS  \n",
       "F1 Score                   0.990389          0.989307  \n",
       "Recall Score               0.991895          0.991612  \n",
       "Precision Score            0.988889          0.987013  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([f1_test2] + [recall_test2] + [precision_test2], columns = activity_label, index = [\"F1 Score\", \"Recall Score\", \"Precision Score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison between the 4 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Avg Precision</th>\n",
       "      <th>Avg Recall</th>\n",
       "      <th>Avg F1</th>\n",
       "      <th>Run Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Validation</th>\n",
       "      <td>0.971686</td>\n",
       "      <td>0.971686</td>\n",
       "      <td>0.971686</td>\n",
       "      <td>0.971686</td>\n",
       "      <td>5.750157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA Validation</th>\n",
       "      <td>0.924710</td>\n",
       "      <td>0.924710</td>\n",
       "      <td>0.924710</td>\n",
       "      <td>0.924710</td>\n",
       "      <td>4.788551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.994335</td>\n",
       "      <td>0.994335</td>\n",
       "      <td>0.994335</td>\n",
       "      <td>0.969628</td>\n",
       "      <td>5.660717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA Test</th>\n",
       "      <td>0.984936</td>\n",
       "      <td>0.984936</td>\n",
       "      <td>0.984936</td>\n",
       "      <td>0.957857</td>\n",
       "      <td>5.188066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Accuracy  Avg Precision  Avg Recall    Avg F1  Run Time\n",
       "Validation      0.971686       0.971686    0.971686  0.971686  5.750157\n",
       "PCA Validation  0.924710       0.924710    0.924710  0.924710  4.788551\n",
       "Test            0.994335       0.994335    0.994335  0.969628  5.660717\n",
       "PCA Test        0.984936       0.984936    0.984936  0.957857  5.188066"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Overall\n",
    "\n",
    "val_res = [accuracy_val, avgprec_val, avgrecall_val, avgf1_val, elapsed_val]\n",
    "pca_val_res = [accuracy_val2, avgprec_val2, avgrecall_val2, avgf1_val2, elapsed_val2]\n",
    "test_res = [accuracy_test, avgprec_test, avgrecall_test, avgf1_test, elapsed_test]\n",
    "pca_test_res = [accuracy_test2, avgprec_test2, avgrecall_test2, avgf1_test2, elapsed_test2]\n",
    "\n",
    "pd.DataFrame([val_res] + [pca_val_res] + [test_res] + [pca_test_res], columns = [\"Accuracy\", \"Avg Precision\", \"Avg Recall\", \"Avg F1\", \"Run Time\"], index = [\"Validation\", \"PCA Validation\", \"Test\", \"PCA Test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, it seems that the overall accuracy / recall / precision / F1 all seem to be better when PCA is not applied to the data, but we will need to compare each individual score to get a better sensing of how the under-represented data are faring. The runtime, however, seem to be better when using the PCA data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STANDING</th>\n",
       "      <th>STAND_TO_SIT</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>SIT_TO_STAND</th>\n",
       "      <th>STAND_TO_LIE</th>\n",
       "      <th>LAYING</th>\n",
       "      <th>LIE_TO_SIT</th>\n",
       "      <th>SIT_TO_LIE</th>\n",
       "      <th>LIE_TO_STAND</th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.900813</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.872865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.989796</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.985386</td>\n",
       "      <td>0.949333</td>\n",
       "      <td>0.944578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall Score</th>\n",
       "      <td>0.945392</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.991597</td>\n",
       "      <td>0.956989</td>\n",
       "      <td>0.956098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision Score</th>\n",
       "      <td>0.860248</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916335</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.979253</td>\n",
       "      <td>0.941799</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 STANDING  STAND_TO_SIT   SITTING  SIT_TO_STAND  STAND_TO_LIE  \\\n",
       "F1 Score         0.900813      0.500000  0.872865           0.0      0.645161   \n",
       "Recall Score     0.945392      0.333333  0.833333           0.0      0.588235   \n",
       "Precision Score  0.860248      1.000000  0.916335           0.0      0.714286   \n",
       "\n",
       "                   LAYING  LIE_TO_SIT  SIT_TO_LIE  LIE_TO_STAND   WALKING  \\\n",
       "F1 Score         0.989796    0.500000    0.583333      0.400000  0.985386   \n",
       "Recall Score     1.000000    0.545455    0.466667      0.285714  0.991597   \n",
       "Precision Score  0.979798    0.461538    0.777778      0.666667  0.979253   \n",
       "\n",
       "                 WALKING_DOWNSTAIRS  WALKING_UPSTAIRS  \n",
       "F1 Score                   0.949333          0.944578  \n",
       "Recall Score               0.956989          0.956098  \n",
       "Precision Score            0.941799          0.933333  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([f1_test2] + [recall_test2] + [precision_test2], columns = activity_label, index = [\"F1 Score\", \"Recall Score\", \"Precision Score\"])\n",
    "pd.DataFrame([f1_val2] + [recall_val2] + [precision_val2], columns = activity_label, index = [\"F1 Score\", \"Recall Score\", \"Precision Score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STANDING</th>\n",
       "      <th>STAND_TO_SIT</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>SIT_TO_STAND</th>\n",
       "      <th>STAND_TO_LIE</th>\n",
       "      <th>LAYING</th>\n",
       "      <th>LIE_TO_SIT</th>\n",
       "      <th>SIT_TO_LIE</th>\n",
       "      <th>LIE_TO_STAND</th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.967851</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994652</td>\n",
       "      <td>0.987835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA F1 Score</th>\n",
       "      <td>0.900813</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.872865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.989796</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.985386</td>\n",
       "      <td>0.949333</td>\n",
       "      <td>0.944578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall Score</th>\n",
       "      <td>0.976109</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA Recall Score</th>\n",
       "      <td>0.945392</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.991597</td>\n",
       "      <td>0.956989</td>\n",
       "      <td>0.956098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision Score</th>\n",
       "      <td>0.959732</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989362</td>\n",
       "      <td>0.985437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA Precision Score</th>\n",
       "      <td>0.860248</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916335</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.979253</td>\n",
       "      <td>0.941799</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     STANDING  STAND_TO_SIT   SITTING  SIT_TO_STAND  \\\n",
       "F1 Score             0.967851      0.444444  0.963504      0.666667   \n",
       "PCA F1 Score         0.900813      0.500000  0.872865      0.000000   \n",
       "Recall Score         0.976109      0.333333  0.956522      0.500000   \n",
       "PCA Recall Score     0.945392      0.333333  0.833333      0.000000   \n",
       "Precision Score      0.959732      0.666667  0.970588      1.000000   \n",
       "PCA Precision Score  0.860248      1.000000  0.916335      0.000000   \n",
       "\n",
       "                     STAND_TO_LIE    LAYING  LIE_TO_SIT  SIT_TO_LIE  \\\n",
       "F1 Score                 0.756757  1.000000    0.740741    0.709677   \n",
       "PCA F1 Score             0.645161  0.989796    0.500000    0.583333   \n",
       "Recall Score             0.823529  1.000000    0.909091    0.733333   \n",
       "PCA Recall Score         0.588235  1.000000    0.545455    0.466667   \n",
       "Precision Score          0.700000  1.000000    0.625000    0.687500   \n",
       "PCA Precision Score      0.714286  0.979798    0.461538    0.777778   \n",
       "\n",
       "                     LIE_TO_STAND   WALKING  WALKING_DOWNSTAIRS  \\\n",
       "F1 Score                 0.421053  1.000000            0.994652   \n",
       "PCA F1 Score             0.400000  0.985386            0.949333   \n",
       "Recall Score             0.285714  1.000000            1.000000   \n",
       "PCA Recall Score         0.285714  0.991597            0.956989   \n",
       "Precision Score          0.800000  1.000000            0.989362   \n",
       "PCA Precision Score      0.666667  0.979253            0.941799   \n",
       "\n",
       "                     WALKING_UPSTAIRS  \n",
       "F1 Score                     0.987835  \n",
       "PCA F1 Score                 0.944578  \n",
       "Recall Score                 0.990244  \n",
       "PCA Recall Score             0.956098  \n",
       "Precision Score              0.985437  \n",
       "PCA Precision Score          0.933333  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([f1_val] +[f1_val2] + [recall_val] + [recall_val2] + [precision_val] + [precision_val2], columns = activity_label, index = [\"F1 Score\", \"PCA F1 Score\", \"Recall Score\", \"PCA Recall Score\", \"Precision Score\", \"PCA Precision Score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the validation set, it appears that generally for most of the scores, the PCA data seem to have a small drop, but some of the less represented data (e.g Stand to Sit) have rise in their precision scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STANDING</th>\n",
       "      <th>STAND_TO_SIT</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>SIT_TO_STAND</th>\n",
       "      <th>STAND_TO_LIE</th>\n",
       "      <th>LAYING</th>\n",
       "      <th>LIE_TO_SIT</th>\n",
       "      <th>SIT_TO_LIE</th>\n",
       "      <th>LIE_TO_STAND</th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.993336</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.992254</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>0.940397</td>\n",
       "      <td>0.895238</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998988</td>\n",
       "      <td>0.997671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA F1 Score</th>\n",
       "      <td>0.978783</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.973838</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.937853</td>\n",
       "      <td>0.997881</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.997149</td>\n",
       "      <td>0.990389</td>\n",
       "      <td>0.989307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall Score</th>\n",
       "      <td>0.995081</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.990719</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA Recall Score</th>\n",
       "      <td>0.988756</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.964424</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.922222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.998369</td>\n",
       "      <td>0.991895</td>\n",
       "      <td>0.991612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision Score</th>\n",
       "      <td>0.991597</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.993794</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997978</td>\n",
       "      <td>0.997207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA Precision Score</th>\n",
       "      <td>0.969008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983438</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954023</td>\n",
       "      <td>0.995772</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.995932</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.987013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     STANDING  STAND_TO_SIT   SITTING  SIT_TO_STAND  \\\n",
       "F1 Score             0.993336      0.945055  0.992254      0.977778   \n",
       "PCA F1 Score         0.978783      0.955556  0.973838      0.954545   \n",
       "Recall Score         0.995081      0.914894  0.990719      0.956522   \n",
       "PCA Recall Score     0.988756      0.914894  0.964424      0.913043   \n",
       "Precision Score      0.991597      0.977273  0.993794      1.000000   \n",
       "PCA Precision Score  0.969008      1.000000  0.983438      1.000000   \n",
       "\n",
       "                     STAND_TO_LIE    LAYING  LIE_TO_SIT  SIT_TO_LIE  \\\n",
       "F1 Score                 0.950820  1.000000    0.944000    0.940397   \n",
       "PCA F1 Score             0.937853  0.997881    0.901639    0.930556   \n",
       "Recall Score             0.966667  1.000000    0.983333    0.946667   \n",
       "PCA Recall Score         0.922222  1.000000    0.916667    0.893333   \n",
       "Precision Score          0.935484  1.000000    0.907692    0.934211   \n",
       "PCA Precision Score      0.954023  0.995772    0.887097    0.971014   \n",
       "\n",
       "                     LIE_TO_STAND   WALKING  WALKING_DOWNSTAIRS  \\\n",
       "F1 Score                 0.895238  1.000000            0.998988   \n",
       "PCA F1 Score             0.886792  0.997149            0.990389   \n",
       "Recall Score             0.824561  1.000000            1.000000   \n",
       "PCA Recall Score         0.824561  0.998369            0.991895   \n",
       "Precision Score          0.979167  1.000000            0.997978   \n",
       "PCA Precision Score      0.959184  0.995932            0.988889   \n",
       "\n",
       "                     WALKING_UPSTAIRS  \n",
       "F1 Score                     0.997671  \n",
       "PCA F1 Score                 0.989307  \n",
       "Recall Score                 0.998136  \n",
       "PCA Recall Score             0.991612  \n",
       "Precision Score              0.997207  \n",
       "PCA Precision Score          0.987013  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([f1_test] +[f1_test2] + [recall_test] + [recall_test2] + [precision_test] + [precision_test2], columns = activity_label, index = [\"F1 Score\", \"PCA F1 Score\", \"Recall Score\", \"PCA Recall Score\", \"Precision Score\", \"PCA Precision Score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the test set similarly to the validation set, it appears that generally for most of the scores, the PCA data seem to have a drop, but some of the less represented data (e.g Stand to Sit) have rise in their precision scores.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52d0e4b0fefd94b2cb6980e387e638c0c22f7eeec79f53bd58ff8a79f97fe231"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
